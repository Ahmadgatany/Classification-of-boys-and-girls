{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Ahmad Gaitani Code ⚡"
      ],
      "metadata": {
        "id": "5zANhLNn-QEV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **A database of 100 children, boys and girls**\n",
        "\n",
        "![boy vs girl .jpeg](data:image/jpeg;base64,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)"
      ],
      "metadata": {
        "id": "ditzFDTs_DOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGSrIFa6tWT-",
        "outputId": "bacd5959-94e4-425e-e163-f153747e0309"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Define the base directory path\n",
        "base_directory = '/content/drive/My Drive/known_faces/'\n",
        "\n",
        "def load_and_resize_image(image_path, size=(150, 150)):\n",
        "    # Open the image file\n",
        "    img = Image.open(image_path)\n",
        "    # Resize the image\n",
        "    img_resized = img.resize(size)\n",
        "    # Convert the image to a NumPy array\n",
        "    img_array = np.array(img_resized)\n",
        "    return img_array\n",
        "\n",
        "# List files in the directory\n",
        "files = os.listdir(base_directory)\n",
        "\n",
        "# Initialize lists to store images and labels\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "# Process each image\n",
        "for file_name in files:\n",
        "    image_path = os.path.join(base_directory, file_name)\n",
        "    try:\n",
        "        # Load and resize the image\n",
        "        image_array = load_and_resize_image(image_path)\n",
        "        # Append image data to X\n",
        "        X.append(image_array)\n",
        "        # Create target label based on the number in the filename\n",
        "        file_number = int(file_name.split('.')[0])\n",
        "        if file_number % 2 == 1:\n",
        "            y.append('boy')\n",
        "        else:\n",
        "            y.append('girl')\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {file_name}: {e}\")\n",
        "\n",
        "# Convert lists to NumPy arrays\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Print the shape of X and y to verify\n",
        "print(f\"X shape: {X.shape}\")\n",
        "print(f\"y shape: {y.shape}\")\n",
        "\n",
        "# Example of how the data looks\n",
        "print(f\"First label: {y[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2cEm3_vuOYS",
        "outputId": "8f707e6b-db9d-4988-bcda-435b9dacc954"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing .ipynb_checkpoints: [Errno 21] Is a directory: '/content/drive/My Drive/known_faces/.ipynb_checkpoints'\n",
            "X shape: (100, 150, 150, 3)\n",
            "y shape: (100,)\n",
            "First label: girl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Normalize image data\n",
        "X = X / 255.0\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y_encoded, test_size=0.3, random_state=42)\n"
      ],
      "metadata": {
        "id": "qlDJCdsFwBJy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n"
      ],
      "metadata": {
        "id": "vaODV-R5yBMW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to one-hot encoded format\n",
        "y_train_cat = to_categorical(y_train)\n",
        "y_val_cat = to_categorical(y_val)"
      ],
      "metadata": {
        "id": "qoTWARqhyHcH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(2, activation='softmax')  # Adjust the number of neurons based on the number of classes\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETVuODZdyKuf",
        "outputId": "cc484f16-ea21-4aee-d6b1-fc06f0ba0aeb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Initialize the ImageDataGenerator with augmentation options\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "# Apply data augmentation to your training data\n",
        "datagen.fit(X_train)"
      ],
      "metadata": {
        "id": "V_Zo5YQw7k0v"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    datagen.flow(X_train, y_train_cat, batch_size=16),\n",
        "    epochs=15,\n",
        "    validation_data=(X_val, y_val_cat),\n",
        "    # steps_per_epoch=len(X_train) // 32\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7-ulFx5x6Zj",
        "outputId": "e2549264-9fdc-477a-ca91-7fd67caaaeb4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7511 - loss: 0.4702 - val_accuracy: 0.7333 - val_loss: 0.6586\n",
            "Epoch 2/15\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 642ms/step - accuracy: 0.7379 - loss: 0.5774 - val_accuracy: 0.7000 - val_loss: 0.5878\n",
            "Epoch 3/15\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 660ms/step - accuracy: 0.7229 - loss: 0.5158 - val_accuracy: 0.6667 - val_loss: 0.5520\n",
            "Epoch 4/15\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7686 - loss: 0.4852 - val_accuracy: 0.6667 - val_loss: 0.5925\n",
            "Epoch 5/15\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 639ms/step - accuracy: 0.8373 - loss: 0.3528 - val_accuracy: 0.6667 - val_loss: 0.7280\n",
            "Epoch 6/15\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 909ms/step - accuracy: 0.6786 - loss: 0.5728 - val_accuracy: 0.7000 - val_loss: 0.7139\n",
            "Epoch 7/15\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 784ms/step - accuracy: 0.8326 - loss: 0.4508 - val_accuracy: 0.7333 - val_loss: 0.7121\n",
            "Epoch 8/15\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 640ms/step - accuracy: 0.7670 - loss: 0.4424 - val_accuracy: 0.6333 - val_loss: 0.6847\n",
            "Epoch 9/15\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 770ms/step - accuracy: 0.7787 - loss: 0.4892 - val_accuracy: 0.7000 - val_loss: 0.6607\n",
            "Epoch 10/15\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7818 - loss: 0.4504 - val_accuracy: 0.7333 - val_loss: 0.7386\n",
            "Epoch 11/15\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 647ms/step - accuracy: 0.7382 - loss: 0.4796 - val_accuracy: 0.7333 - val_loss: 0.7049\n",
            "Epoch 12/15\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 978ms/step - accuracy: 0.7484 - loss: 0.4247 - val_accuracy: 0.7333 - val_loss: 0.7606\n",
            "Epoch 13/15\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 750ms/step - accuracy: 0.8014 - loss: 0.4639 - val_accuracy: 0.7000 - val_loss: 0.8113\n",
            "Epoch 14/15\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 899ms/step - accuracy: 0.8120 - loss: 0.4065 - val_accuracy: 0.7000 - val_loss: 0.7871\n",
            "Epoch 15/15\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.8038 - loss: 0.3985 - val_accuracy: 0.7000 - val_loss: 0.6743\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "val_loss, val_acc = model.evaluate(X_val, y_val_cat)\n",
        "print(f\"Validation accuracy: {val_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJH1wAFj8Rzj",
        "outputId": "048cb502-ca05-4718-a1a8-761ef811a2e4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - accuracy: 0.7000 - loss: 0.6743\n",
            "Validation accuracy: 0.7000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save('/content/drive/My Drive/cnn_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8Yo1mGHzW1h",
        "outputId": "7ee45b00-7975-40e0-e874-a6412d681e18"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Create and fit the label encoder\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(y)  # Fit on your training labels\n",
        "\n",
        "# Save the label encoder classes\n",
        "np.save('/content/drive/My Drive/label_encoder_classes.npy', label_encoder.classes_)\n"
      ],
      "metadata": {
        "id": "oxNqhHe00RqX"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the saved model\n",
        "model = tf.keras.models.load_model('/content/drive/My Drive/cnn_model.h5')\n",
        "\n",
        "# Define the function to load, resize, and preprocess the new image\n",
        "def preprocess_image(image_path, size=(150, 150)):\n",
        "    img = Image.open(image_path)\n",
        "    img_resized = img.resize(size)\n",
        "    img_array = np.array(img_resized)\n",
        "    img_array = img_array / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    return img_array\n",
        "\n",
        "# Load the label encoder classes\n",
        "label_classes = np.load('/content/drive/My Drive/label_encoder_classes.npy')\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.classes_ = label_classes\n",
        "\n",
        "# Path to the new image\n",
        "new_image_path = 'Ahmed.jpg'\n",
        "\n",
        "# Preprocess the new image\n",
        "new_image_array = preprocess_image(new_image_path)\n",
        "\n",
        "# Make a prediction\n",
        "prediction = model.predict(new_image_array)\n",
        "\n",
        "# Decode the prediction\n",
        "predicted_class = np.argmax(prediction, axis=1)\n",
        "predicted_label = label_encoder.inverse_transform(predicted_class)\n",
        "\n",
        "# Print the result\n",
        "print(f\"Predicted label: {predicted_label[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFmkMBXA1LvD",
        "outputId": "791e8467-b72b-4199-e208-72f00d231afa"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
            "Predicted label: boy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KpLDb6T41hks"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}